1.  Основные свойства численных методов.(数字方法的主要特性)
2.  Этапы решения задач численными методами.(使用数值方法解决问题)
3.  Решение систем линейных уравнений. Метод Гаусса.(高斯法)
4.  Метод Гаусса с выбором главного элемента.(高斯消元法)
5. Метод Гаусса-Зейделя.(高斯赛德尔迭代)
6. Метод простой итерации.(简单迭代法)
7.  Условия сходимости итерационных методов решения СЛАУ.(迭代法解线性方程组的收敛性)
8. Методы решения нелинейных уравнений. Метод касательных.(解决非线性方程的方法。切线法。)
9.  Метод деления отрезка пополам.(二分法)
10. Методы решения нелинейных уравнений. Метод простой итерации.(解决非线性方程,简单迭代法)
11. Методы решения нелинейных уравнений. Метод хорд.(弦截法)
12. Метод секущих.(割线法（又称为切线法)
13. Методы решения системы нелинейных уравнений. Метод Ньютона.
14. Методы решения системы нелинейных уравнений. Метод простой итерации.
15. Интерполяция функции.(插值)
16. Интерполяционная формула Лагранжа.(拉格朗日插值公式)
17. Интерполяционные формулы Ньютона.(牛顿插值公式)
18. Конечные и разделенные разности.(有限差商和分裂差商)
19. Интерполяционные формулы Гаусса, Стирлинга, Бесселя.(高斯插值公式、斯特林插值公式和贝塞尔插值公式)
20. Аппроксимация функции методом наименьших квадратов.(最小二乘法)
21. Линейное приближение.(线性逼近)
22. Квадратичное приближение.(二次逼近)
23. Аппроксимация степенной, экспоненциальной и логарифмической  функций(幂函数、指数函数和对数函数的逼近)
24. Численное интегрирование. Метод прямоугольников.(数值积分。矩形方法)
25. Численное интегрирование. Метод трапеций.(数值积分,梯形法)
26. Численное интегрирование. Метод Симпсона.(辛普森法则)
27. Решения задачи Коши. Методы Эйлера(柯西问题,欧拉方法)
28. Решения задачи Коши. Методы Рунге-Кутта.(龙格-库塔方法)
29. Многошаговые методы. Метод Адамса.(多步方法,亚当斯（Adams）方法)
30. Многошаговые методы. Метод Милна.(米尔恩（Milne）方法)

# 1.Основные свойства численных методов.(数字方法的主要特性)
近似性：数字方法使用近似来对问题的解进行估计。通常，它们将问题分解为更简单的部分或对连续函数进行离散化，以获得数值表示。

误差：数字方法存在误差，即精确解与其近似解之间的差异。数字方法的目标是通过改进近似来减小误差。

稳定性：稳定性是数字方法的一个特性，它确保输入数据的小变化或计算中的舍入不会导致解的显著变化。稳定的方法保证结果的可靠性和准确性。

收敛性：收敛性描述了数字方法在增加计算资源（如迭代次数或步长）时逐渐接近精确解的行为。良好的数字方法在增加计算资源的情况下能够收敛到精确解。

效率：效率评估使用数字方法解决问题所需的计算成本。优秀的数字方法在最小的计算成本下提供高精度的结果。

适用性：数字方法可应用于各种领域的问题，包括数学、物理、工程、经济等。它们可以解决没有解析解或解析解过于复杂或昂贵的复杂问题。

# 2. Этапы решения задач численными методами.(使用数值方法解决问题)
问题建模：将实际问题转化为数学模型。这涉及确定问题的目标、边界条件、约束条件和输入数据等。

离散化：将连续的问题转化为离散的形式。这包括将空间和时间划分为离散的网格或网点，以便在这些点上进行计算。

近似方法选择：选择适当的数值方法来近似问题的解。这取决于问题的性质和要求，可能涉及差分方法、插值方法、优化算法等。

算法设计：设计实现所选数值方法的计算算法。这包括确定迭代方案、数值格式和计算步骤等。

计算过程：执行计算算法以获得数值解。这涉及输入初始条件、迭代计算并更新解，直到满足收敛准则或达到预定的计算步数。

结果评估：评估数值解的准确性和可靠性。这包括分析解的误差、收敛性以及与实际问题的比较等。

结果解释：解释数值解的物理或实际意义，并根据需要进行结果的可视化和解释。

误差分析和改进：分析误差来源并识别改进的可能性。这可能涉及调整离散化参数、改进算法或选择更精确的数值方法等。

# 3. Решение систем линейных уравнений. Метод Гаусса.(高斯法)
消元阶段：将线性方程组表示为增广矩阵，其中包含系数矩阵和右侧常数向量。通过一系列行变换，将增广矩阵转化为上三角矩阵，其中主对角线上的元素都不为零。

回代阶段：从最后一行开始，逐步求解变量的值。将求解出的变量值代入上面的方程，依次向上进行回代，直到求解出所有变量的值。

# 4. Метод Гаусса с выбором главного элемента.(高斯消元法)
首先，将线性方程组表示为增广矩阵，其中包含系数矩阵和右侧常数向量。

在每个消元步骤中，选择主元元素，即在当前列中绝对值最大的元素。这样可以减小舍入误差并提高计算的准确性。

如果选择的主元不在当前行，需要进行行交换，将主元所在的行移到当前行的位置。

使用所选的主元元素将当前列的其他元素消为零。为此，将当前行乘以适当的倍数，并从下面的行中减去该倍数乘以主元所在列的元素。

重复上述步骤，逐渐将增广矩阵转化为上三角形式。

在回代阶段，从最后一行开始，逐步求解变量的值。将求解出的变量值代入上面的方程，依次向上进行回代，直到求解出所有变量的值。

通过使用主元选择，高斯消元法可以减小舍入误差并提高数值解的准确性。这种方法对于处理病态（ill-conditioned）的方程组尤为有用，其中系数矩阵的条件数较大。

# 5. Метод Гаусса-Зейделя.(高斯赛德尔迭代)
高斯-塞德尔方法是一种逐步逼近的方法，它在每个迭代步骤中使用最新的估计值来更新解向量。相比于高斯消元法，高斯-塞德尔方法的收敛速度更快，尤其在对角元素相对较大的对称正定矩阵中效果更好。

然而，需要注意的是，高斯-塞德尔方法并不总是收敛。对于某些线性方程组，可能需要进一步的技术手段来确保收敛性和稳定性。

# 6. Метод простой итерации.(简单迭代法)

# 7. Условия сходимости итерационных методов решения СЛАУ.(迭代法解线性方程组的收敛性)
矩阵范数条件：迭代矩阵的范数应小于1。这是最常见的收敛条件之一。常见的矩阵范数有1-范数、2-范数和无穷大范数等。

对角占优条件：如果系数矩阵的每一行（或每一列）的对角元素的绝对值大于等于该行（或该列）其他元素绝对值之和，那么称系数矩阵满足对角占优条件。对角占优条件有助于确保迭代法的收敛性。

正定矩阵条件：如果系数矩阵是对称正定的，那么迭代法通常会收敛。对称正定矩阵具有一些特殊性质，可以确保迭代法的收敛性。

对称性条件：对称的系数矩阵通常有助于迭代法的收敛。对称矩阵具有一些特殊的性质，可以简化迭代算法并提高收敛速度。

# 8. Методы решения нелинейных уравнений. Метод касательных.(解决非线性方程的方法。切线法。)
方法在非线性方程求解中是一种常用的数值方法之一。也称为牛顿迭代法。它通过利用函数的切线来逐步逼近方程的根。具体步骤如下：

选择初始估计值x₀。

计算函数在 $x₀$ 处的值 $f(x₀)$ 和导数在x₀处的值 $f'(x₀)$。

使用切线的斜率来计算下一个近似根x₁。计算公式如下：
$$x₁ = x₀ - f(x₀)/f'(x₀)$$

重复步骤2和步骤3，计算下一个近似根，直到满足预先设定的停止准则，如误差小于一定阈值或达到最大迭代次数。

返回最终的近似根。

牛顿法的优点是收敛速度通常很快，尤其是当初始估计值接近根时。然而，它也有一些注意事项：

初始估计值的选择很重要，不同的初始估计值可能会导致不同的根或迭代过程不收敛。
在某些情况下，牛顿法可能会陷入局部最小值或发散，特别是在函数具有复杂性或奇点的情况下。
对于方程组的求解，需要使用扩展的牛顿法，也称为牛顿-拉夫逊法。

# 9.  Метод деления отрезка пополам.(二分法)
二分法（又称为区间减半法或二分搜索法）是一种常用的数值方法，用于解决非线性方程的数值逼近。它通过将待求解的区间逐步减半，直到找到方程的根或达到预定的精度要求。具体步骤如下：

选择一个包含根的初始区间 $[a, b]$，确保方程在该区间内是连续的且根存在。

计算区间中点 $c = (a + b) / 2$。

计算函数在中点 c 处的值 $f(c)$。

检查 $f(c)$ 是否接近于零，或是否满足预定的精度要求。如果满足条件，则 c 是方程的近似根，算法结束。

如果 $f(c)$ 与零的符号相同，则将 c 作为新的右区间边界 b，并返回步骤2。

如果 $f(c)$ 与零的符号相反，则将 c 作为新的左区间边界 a，并返回步骤2。

重复步骤2到步骤6，直到找到方程的根或达到预定的精度要求。

二分法的优点是简单易懂，每一步都可以确保区间中包含根，并且收敛速度相对较快。然而，它也有一些注意事项：

初始区间的选择很重要，不同的初始区间可能导致不同的根或迭代过程不收敛。
如果方程在区间的端点上没有变号，二分法可能无法找到根。
对于具有多个根的方程，二分法只能找到一个根。

# 10. Методы решения нелинейных уравнений. Метод простой итерации.(解决非线性方程,简单迭代法)
它通过将原始方程转化为等价的迭代形式，逐步逼近方程的根。具体步骤如下：

将非线性方程表示为函数的形式，即 $f(x) = 0$。

将方程转化为迭代形式，即 $x = g(x)$，其中 $g(x)$ 是新的函数形式。

选择初始估计值 $x₀$。

通过以下迭代步骤更新估计值 x 的值：
$$x₁ = g(x₀)$$
$$x₂ = g(x₁)$$
$$...$$
$$xₙ₊₁ = g(xₙ)$$

重复步骤4，直到满足预设的停止准则，如误差小于一定阈值或达到最大迭代次数。

返回最终的近似根 $xₙ$。

简单迭代法的成功与否取决于迭代函数 g(x) 的选择和初始估计值 x₀ 的选取。对于迭代函数 $g(x)$，需要满足以下条件以确保收敛性：

在根附近，$g(x)$ 的导数的绝对值小于 1，即 $|g'(x)| < 1$。
$g(x)$ 在根附近是连续的。
此外，初始估计值 x₀ 的选择也很重要。不同的初始估计值可能导致不同的根或迭代过程不收敛。

需要注意的是，简单迭代法可能遇到收敛速度慢的问题，特别是在接近根的情况下。为了提高迭代的收敛速度，可以使用其他更高级的迭代方法，如牛顿法或割线法。

# 11. Методы решения нелинейных уравнений. Метод хорд.(弦截法)
它利用方程的两个近似根之间的线性插值来逼近方程的根。具体步骤如下：

选择两个初始估计值 $x₀$ 和 $x₁$，确保方程在这两个点之间有根存在。

计算函数在这两个点上的值：$f(x₀)$ 和 $f(x₁)$。

使用线性插值来计算下一个近似根 x₂。根据直线插值公式，计算如下：
$$x₂ = x₁ - f(x₁) * (x₁ - x₀) / (f(x₁) - f(x₀))$$

重复步骤2和步骤3，计算下一个近似根，直到满足预设的停止准则，如误差小于一定阈值或达到最大迭代次数。

返回最终的近似根。

弦截法的优点是在每一步都利用了两个近似根，相对于简单迭代法的单个近似根，收敛速度更快。然而，它也有一些注意事项：

初始估计值的选择很重要，不同的初始估计值可能导致不同的根或迭代过程不收敛。
如果初始估计值选得不合适，弦截法可能会发散而不收敛。
弦截法可能在方程的某些区域或特定类型的方程中出现振荡现象。

# 12. Метод секущих.(割线法（又称为切线法)
它是在近似根处使用切线来逼近方程的根。与弦截法类似，割线法不需要提供两个初始估计值，而是使用一个初始估计值和前一次迭代的值来计算下一个近似根。具体步骤如下：

选择两个初始估计值 $x₀$ 和 $x₁$，确保方程在这两个点之间有根存在。

计算函数在这两个点上的值：$f(x₀)$ 和 $f(x₁)$。

使用线性插值（割线）来计算下一个近似根 x₂。根据线性插值的公式，计算如下：
$$x₂ = x₁ - f(x₁) * (x₁ - x₀) / (f(x₁) - f(x₀))$$

重复步骤2和步骤3，计算下一个近似根，直到满足预设的停止准则，如误差小于一定阈值或达到最大迭代次数。

返回最终的近似根。

割线法的特点是在每一步迭代中，它使用了函数在两个点上的斜率来逼近方程的根。与弦截法相比，割线法的收敛速度可能更快，但计算成本也更高。然而，割线法也有一些注意事项：

初始估计值的选择很重要，不同的初始估计值可能导致不同的根或迭代过程不收敛。
如果初始估计值选得不合适，割线法可能会发散而不收敛。
割线法可能在方程的某些区域或特定类型的方程中出现振荡现象。

# 13. Методы решения системы нелинейных уравнений. Метод Ньютона.
它利用方程的局部线性逼近来迭代地逼近方程组的解。具体步骤如下：

确定初始估计向量 $x₀$。

计算方程组在初始估计向量处的函数值向量 $f(x₀)$。

计算方程组在初始估计向量处的雅可比矩阵 $J(x₀)$。

解一个线性方程组 $J(x₀)∆x = -f(x₀)$，其中 ∆x 是待求解的增量向量。

计算下一个近似解向量 $x₁ = x₀ + ∆x$。

重复步骤2到步骤5，直到满足预设的停止准则，如误差小于一定阈值或达到最大迭代次数。

返回最终的近似解向量。

牛顿法的核心思想是通过在每次迭代中使用当前解向量的局部线性逼近来逐步接近方程组的解。它通常具有快速的收敛速度，尤其在初始估计向量接近解向量时。然而，牛顿法也有一些注意事项：

初始估计向量的选择很重要，不同的初始估计向量可能导致不同的解或迭代过程不收敛。
在计算雅可比矩阵时，可能需要数值方法来近似计算，特别是对于复杂的方程组。
如果雅可比矩阵在某些点上奇异或不可逆，牛顿法可能无法收敛或产生错误的结果。

# 14. Методы решения системы нелинейных уравнений. Метод простой итерации.
它通过将原始方程组转化为等价的迭代形式，逐步逼近方程组的解。具体步骤如下：

将非线性方程组表示为向量函数的形式，即 $F(x) = 0$，其中 x 是未知向量，$F(x)$ 是方程组的向量函数。

将方程组转化为迭代形式，即 $x = G(x)$，其中 $G(x)$ 是新的向量函数形式。

选择初始估计向量 $x₀$。

通过以下迭代步骤更新估计向量 x 的值：
$$x₁ = G(x₀)$$
$$x₂ = G(x₁)$$
$$...$$
$$xₙ₊₁ = G(xₙ)$$

重复步骤4，直到满足预设的停止准则，如误差小于一定阈值或达到最大迭代次数。

返回最终的近似解向量 $xₙ$。

简单迭代法的成功与否取决于迭代函数 $G(x)$ 的选择和初始估计向量 $x₀$ 的选取。对于迭代函数 $G(x)$，需要满足以下条件以确保收敛性：

在解附近，$G(x)$ 的雅可比矩阵的谱半径小于 1，即所有特征值的绝对值小于 1。
$G(x)$ 在解附近是连续的。
此外，初始估计向量 $x₀$ 的选择也很重要。不同的初始估计向量可能导致不同的解或迭代过程不收敛。

需要注意的是，简单迭代法可能遇到收敛速度慢的问题，特别是在接近解的情况下。为了提高迭代的收敛速度，可以使用其他更高级的迭代方法，如牛顿法或割线法。

# 15. Интерполяция функции.(插值)
插值是一种数值分析方法，用于估计在已知数据点之间的未知函数值。插值的目标是构建一个逼近原始函数的插值函数，以在数据点之间进行预测和估计。插值方法通常基于已知数据点的函数值来构造逼近函数。

在插值过程中，常见的方法之一是多项式插值。多项式插值使用多项式函数来逼近原始函数。其中，拉格朗日插值和牛顿插值是两种常见的多项式插值方法。

拉格朗日插值：拉格朗日插值使用基于拉格朗日多项式的方法来逼近函数。它通过构造一个满足已知数据点和函数值的多项式函数，然后使用该多项式来估计在其他点上的函数值。

牛顿插值：牛顿插值使用差商（divided differences）的概念来逼近函数。差商是一种计算多项式系数的方法，基于已知数据点的函数值。通过计算差商表和使用差商来构建多项式，可以进行插值预测。

除了多项式插值，还有其他插值方法，如样条插值和分段线性插值。这些方法根据具体情况和要求，选择不同的逼近函数或插值算法。

插值方法的选择取决于数据点的分布和函数的特性。在实际应用中，需要考虑插值的精度、计算效率和平滑性等因素。此外，插值可能受到截断误差和插值误差的影响，因此需要在使用插值结果时进行适当的误差估计和控制。

总之，插值是一种估计函数在数据点之间值的常见数值方法，可应用于数据分析、函数逼近和数值模拟等领域。根据具体情况和要求，选择适当的插值方法和逼近函数，以获得准确和可靠的插值结果。


# 16. Интерполяционная формула Лагранжа.(拉格朗日插值公式)
拉格朗日插值公式是一种常用的插值方法，用于通过已知数据点构建逼近函数。它使用拉格朗日多项式来逼近原始函数。拉格朗日插值公式的基本思想是构造一个满足已知数据点和函数值的多项式函数，然后使用该多项式来估计在其他点上的函数值。

拉格朗日插值公式的具体形式如下：

给定 $n+1$ 个不同的数据点 $(x₀, y₀), (x₁, y₁), ..., (xₙ, yₙ)$，其中 $xi￥ 是数据点的横坐标，$yi$ 是对应的函数值。

拉格朗日插值多项式 $L(x)$ 可以表示为：

$$L(x) = y₀ * l₀(x) + y₁ * l₁(x) + ... + yₙ * lₙ(x)$$

其中，$lᵢ(x)$ 是拉格朗日基函数，定义为：

$$lᵢ(x) = Π[j=0, j≠i]ⁿ (x - xⱼ) / (xᵢ - xⱼ)$$

上述公式中，Π 表示乘积运算符，$lᵢ(x)$ 是一个关于 x 的多项式函数，它满足 $lᵢ(xⱼ) = δᵢⱼ$，其中 $δᵢⱼ$ 是克罗内克 δ 符号，当 i=j 时取值为 1，否则取值为 0。

使用拉格朗日插值公式，可以通过已知数据点的函数值来构建逼近函数，从而在其他点上估计函数的值。插值误差受到数据点的分布和函数的特性影响，因此在实际应用中，需要考虑选择合适的插值方法和逼近函数，以获得准确和可靠的插值结果。

# 17. Интерполяционные формулы Ньютона.(牛顿插值公式)
牛顿插值公式是一种常见的插值方法，用于通过已知数据点构建逼近函数。与拉格朗日插值不同，牛顿插值使用差商（divided differences）的概念来逼近函数。牛顿插值公式的基本思想是构建一个满足已知数据点和函数值的多项式函数，然后使用该多项式来估计在其他点上的函数值。

牛顿插值公式的一般形式如下：

给定 n+1 个不同的数据点 $(x₀, y₀), (x₁, y₁), ..., (xₙ, yₙ)$，其中 $xi$ 是数据点的横坐标，$yi$ 是对应的函数值。

牛顿插值多项式 $N(x)$ 可以表示为：

$$N(x) = c₀ + c₁(x - x₀) + c₂(x - x₀)(x - x₁) + ... + cₙ(x - x₀)(x - x₁)...(x - xₙ₋₁)$$

其中，$c₀, c₁, ..., cₙ$ 是差商的系数。

差商是一种递归定义的概念，用于计算牛顿插值多项式中的系数。差商的定义如下：

$$f[x₀] = y₀$$

$$f[x₁] = y₁$$

$$f[x₂] = (f[x₁] - f[x₀]) / (x₁ - x₀)$$

$$f[x₃] = (f[x₂] - f[x₁]) / (x₂ - x₁)$$

$$...$$

$$f[xₙ] = (f[xₙ₋₁] - f[xₙ₋₂]) / (xₙ - xₙ₋₁)$$

上述公式中，$f[xᵢ]$ 表示差商，表示数据点 $(x₀, y₀), (x₁, y₁), ..., (xᵢ, yᵢ)$ 对应的差商，其中 i=0,1,...,n。

通过计算差商，可以逐步求得牛顿插值多项式的系数。然后，使用该多项式可以在其他点上估计函数的值。

牛顿插值公式的优点是可以在插值过程中动态地添加新的数据点，而不需要重新计算整个插值多项式。这使得牛顿插值方法更加灵活和高效。

# 18. Конечные и разделенные разности.(有限差商和分裂差商)
## 有限差商：
有限差商是指在插值问题中使用的差分近似导数的方法。它可以通过函数在数据点附近的差分来估计导数的值。有限差商的基本思想是使用函数在不同点上的函数值之间的差分来近似导数的值。常见的有限差商包括前向差商、后向差商和中心差商。
### 前向差商：
前向差商使用函数在相邻数据点的差分来估计导数的值，通过计算函数在 $x₀$ 和 $x₀ + h$ 处的差商来近似导数的值。
### 后向差商：
后向差商与前向差商类似，但是它使用函数在 $x₀$ 和 $x₀ - h$ 处的差商来近似导数的值。
### 中心差商：
中心差商是通过函数在相邻数据点的差分来近似导数的值，它使用函数在 $x₀ - h$ 和 $x₀ + h$ 处的差商。
## 分裂差商：
分裂差商是用于构建插值多项式的概念。它通过递归地计算差商来构造逼近函数。分裂差商的基本思想是使用函数在不同点上的函数值之间的差商来递归地构造插值多项式。常见的分裂差商包括牛顿差商和斯特林差商。
### 牛顿差商：
牛顿差商是通过递归计算差商来构建插值多项式的方法。它使用函数在不同点上的函数值之间的差商来递归地计算插值多项式的系数。
### 斯特林差商：
斯特林差商是一种改进的差商计算方法，它使用对称的差商点来构造插值多项式。它通过函数在不同点上的函数值之间的差商来递归地计算插值多项式的系数。

# 19. Интерполяционные формулы Гаусса, Стирлинга, Бесселя.(高斯插值公式、斯特林插值公式和贝塞尔插值公式)
## 高斯插值公式（Gauss interpolation formula）：
高斯插值公式是由德国数学家卡尔·高斯（Carl Friedrich Gauss）提出的一种插值方法。它利用高斯基函数和拉格朗日插值多项式的思想来构建插值多项式。高斯插值公式可以在给定数据点上生成一组插值节点，通过在这些节点上构造插值多项式来逼近原始函数。

## 斯特林插值公式（Stirling interpolation formula）：
斯特林插值公式是以苏格兰数学家詹姆斯·斯特林（James Stirling）的名字命名的一种插值方法。它是一种使用斯特林差商的插值公式。斯特林插值公式通过递归计算斯特林差商来构造插值多项式，以逼近原始函数。

## 贝塞尔插值公式（Bessel interpolation formula）：
贝塞尔插值公式是以德国数学家弗里德里希·贝塞尔（Friedrich Bessel）的名字命名的一种插值方法。它使用贝塞尔基函数和贝塞尔多项式的思想来构建插值多项式。贝塞尔插值公式可以通过一组给定的数据点生成插值节点，并通过在这些节点上构造插值多项式来逼近原始函数。

# 20. Аппроксимация функции методом наименьших квадратов.(最小二乘法)
最小二乘法是一种常用的函数逼近方法，用于通过已知数据点拟合一个函数模型。它的基本思想是通过最小化数据点与拟合函数之间的残差平方和来确定最佳拟合函数的参数。

最小二乘法的步骤如下：

假设要拟合的函数模型为 $y = f(x, a₁, a₂, ..., an)$，其中 x 是自变量，$a₁, a₂, ..., an$ 是待确定的参数。

收集一组已知的数据点 $(x₁, y₁), (x₂, y₂), ..., (xₙ, yₙ)$，其中 xi 是自变量的取值，yi 是对应的函数值。

构建一个目标函数，即残差平方和，定义为 $$S(a₁, a₂, ..., an) = Σ(yᵢ - f(xᵢ, a₁, a₂, ..., an))²$$。

最小二乘法的目标是通过最小化目标函数 $$S(a₁, a₂, ..., an) 来确定最佳参数值 a₁, a₂, ..., an$$。

求解最小化目标函数的参数，可以通过求偏导数并令其为零来得到最佳参数的估计值。

通过得到的最佳参数值，可以构建拟合函数模型 y = f(x, a₁, a₂, ..., an)。

最小二乘法可以用于线性和非线性函数拟合。对于线性拟合，拟合函数模型是线性的；对于非线性拟合，拟合函数模型是非线性的，参数的估计需要使用数值优化方法进行求解。

# 21. Линейное приближение.(线性逼近)
线性逼近是一种通过使用线性函数来近似原始函数的方法。它基于线性函数在给定点附近的斜率来逼近原始函数的局部行为。

线性逼近的基本思想是选择一条直线，使其尽可能地接近原始函数，并且在给定点处与原始函数具有相同的斜率。这条直线可以通过选择合适的截距和斜率来确定。

线性逼近可以表示为以下形式的线性函数：$y = mx + b$，其中 m 是斜率，$b$ 是截距。通过调整斜率和截距的值，线性逼近可以更好地拟合原始函数。

线性逼近在许多领域中都有广泛的应用。它可以用于数据拟合、函数逼近、趋势分析等。线性逼近的优势在于简单性和可解释性，它可以提供对原始函数在给定点附近行为的直观理解。

# 22. Квадратичное приближение.(二次逼近)
二次逼近是一种通过使用二次函数来近似原始函数的方法。它基于二次函数在给定点附近的曲率和斜率来逼近原始函数的局部行为。

二次逼近的基本思想是选择一个二次函数，使其尽可能地接近原始函数，并且在给定点处与原始函数具有相同的曲率和斜率。这个二次函数可以通过选择合适的系数来确定。

二次逼近可以表示为以下形式的二次函数：$y = ax^2 + bx + c$，其中 a 是二次项系数，b 是一次项系数，c 是常数项。通过调整这些系数的值，二次逼近可以更好地拟合原始函数。

二次逼近相比于线性逼近更加灵活和准确，它可以更好地拟合原始函数的局部曲线特性。它适用于在给定点附近需要更精确逼近的函数。

二次逼近在许多领域中都有广泛的应用。它可以用于数据拟合、曲线拟合、近似函数的构建等。二次逼近的优势在于能够更准确地描述原始函数的局部曲线形状。

然而，与线性逼近一样，二次逼近也具有局限性。它只能近似原始函数的局部行为，并且可能对非线性或高度复杂的函数不够准确。

# 23. Аппроксимация степенной, экспоненциальной и логарифмической  функций(幂函数、指数函数和对数函数的逼近)
对于幂函数、指数函数和对数函数的逼近，我们可以使用不同的方法进行近似。

对于幂函数（power function），可以使用线性逼近或多项式逼近。通过选择合适的幂次，可以使用线性函数或多项式函数来近似幂函数的行为。

对于指数函数（exponential function），可以使用泰勒级数展开或使用指数逼近方法。泰勒级数展开可以将指数函数表示为无穷级数的形式，通过截断级数可以得到近似值。指数逼近方法则利用指数函数与多项式函数之间的关系来进行逼近。

对于对数函数（logarithmic function），可以使用线性逼近或多项式逼近。通过选择适当的变量变换，可以将对数函数转化为线性形式或多项式形式，从而进行逼近。

在实际应用中，选择适当的逼近方法取决于所需的精度和逼近范围。

# 24. Численное интегрирование. Метод прямоугольников.(数值积分。矩形方法)
数值积分是一种通过将曲线下的区域划分为多个小矩形，并对每个矩形的面积进行近似计算来求解定积分的方法。其中一种常用的数值积分方法是矩形法。

矩形法（又称为矩形逼近法或矩形规则）将曲线下的区域划分为若干个等宽的小矩形，然后通过计算每个矩形的面积之和来近似计算定积分的值。

矩形法有三种常见的形式：左矩形法、右矩形法和中矩形法。这些方法的区别在于选择每个小矩形的高度。

左矩形法：每个小矩形的高度取自该小矩形左侧的函数值。

右矩形法：每个小矩形的高度取自该小矩形右侧的函数值。

中矩形法：每个小矩形的高度取自该小矩形中间的函数值。

矩形法的基本步骤如下：

将曲线下的区域划分为若干个小矩形，确定每个小矩形的宽度（通常取等宽）。

选择适当的矩形法（左矩形法、右矩形法或中矩形法）。

计算每个小矩形的高度，即根据选定的矩形法从函数上选择相应的函数值。

计算每个小矩形的面积，即宽度乘以高度。

对所有小矩形的面积进行求和，得到定积分的近似值。

矩形法是一种简单直观的数值积分方法，特别适用于函数在给定区间上变化较小或函数较为规则的情况。然而，矩形法的精度通常较低，尤其是在函数变化较大或函数非常不规则的情况下。

# 25. Численное интегрирование. Метод трапеций.(数值积分,梯形法)
梯形法则通过将积分区间分成若干个小梯形，然后计算这些小梯形的面积之和来近似计算定积分。具体步骤如下：

将积分区间 $[a, b]$ 分成n个小区间，每个小区间的宽度为 $h = (b - a) / n$ 。这将形成 $n+1$ 个点：$a, a+h, a+2h, ..., b $ 。

在这些点上计算函数的值，得到对应的函数值列表。

对于每个小区间，计算其两个端点处函数值的平均值，然后乘以小区间的宽度h。这样就得到了该小区间内梯形的面积。

将所有小区间内的梯形面积相加，得到近似的定积分值。

随着n的增加，使用梯形法则的近似结果会越来越接近真实的定积分值。但需要注意的是，梯形法则仍然是一种近似方法，其精度受到区间划分的密度和函数的性质的影响。

# 26. Численное интегрирование. Метод Симпсона.(辛普森法则)
辛普森法则通过将积分区间分成若干个小区间，然后在每个小区间内使用二次多项式来逼近被积函数，从而近似计算定积分。具体步骤如下：

将积分区间 $[a, b]$ 分成n个小区间，每个小区间的宽度为 $h = (b - a) / n$。这将形成 $n+1$ 个点：$a, a+h, a+2h, ..., b$。

在这些点上计算函数的值，得到对应的函数值列表。

将每个相邻的两个小区间看作一个二次多项式的一部分，通过插值的方式构造该二次多项式。

对于每个二次多项式，计算其在小区间内的积分。这可以通过辛普森公式来计算：对于每个小区间 $[a_i, a_i+1]$ ，积分的近似值为 $$(h/6) * (f(a_i) + 4f(a_i + h/2) + f(a_i+1))$$

将所有小区间内的积分近似值相加，得到近似的定积分值。

辛普森法则相较于梯形法则具有更高的精度，尤其适用于曲线较为平滑的函数。同样地，使用更多的小区间(n的值增加)可以提高辛普森法则的精度。

# 27. Решения задачи Коши. Методы Эйлера(柯西问题,欧拉方法)
欧拉方法是一种简单的迭代方法，通过逐步逼近求解常微分方程的解。具体步骤如下：

给定常微分方程的初值问题，即给定初始条件 $y(t₀) = y₀$，其中 t₀ 是初始时刻，y₀ 是初始值。

将时间区间 $[t₀, t₁]$ 分成若干个小时间步长，每个时间步长的宽度为 h。选择适当的步长 h。

使用欧拉方法进行迭代计算。对于每个时间步长，根据常微分方程的形式，使用当前时刻的函数值和导数来估计下一个时刻的函数值。这可以通过以下公式实现：$$y(tᵢ₊₁) = y(tᵢ) + h * f(tᵢ, y(tᵢ))$$ 其中 f(t, y) 是常微分方程的右侧函数。

重复步骤 3，直到达到所需的终止时间 $t₁$。

欧拉方法的精度相对较低，但它是一种简单易实现的方法。可以通过减小时间步长 h 来提高欧拉方法的精度，但这会增加计算量。对于某些常微分方程，欧拉方法可能会出现数值不稳定的问题。

# 28. Решения задачи Коши. Методы Рунге-Кутта.(龙格-库塔方法)
龙格-库塔方法是一种迭代方法，通过逐步逼近求解常微分方程的解。具体步骤如下：

给定常微分方程的初值问题，即给定初始条件 $y(t₀) = y₀$，其中 $t₀$ 是初始时刻，$y₀$ 是初始值。

将时间区间 $[t₀, t₁]$ 分成若干个小时间步长，每个时间步长的宽度为 h。选择适当的步长 h。

使用龙格-库塔方法进行迭代计算。对于每个时间步长，根据常微分方程的形式，使用当前时刻的函数值和导数来估计下一个时刻的函数值。这可以通过多个中间步骤来实现。

龙格-库塔方法的一般形式是根据权重系数计算加权平均值。具体而言，对于一个步长为 h，当前时刻为 tᵢ，函数值为 yᵢ 的情况，龙格-库塔方法的迭代公式如下：

$$k₁ = h * f(tᵢ, yᵢ)$$
$$k₂ = h * f(tᵢ + h/2, yᵢ + k₁/2)$$
$$k₃ = h * f(tᵢ + h/2, yᵢ + k₂/2)$$
$$k₄ = h * f(tᵢ + h, yᵢ + k₃)$$

$$y(tᵢ₊₁) = yᵢ + (k₁ + 2k₂ + 2k₃ + k₄)/6$$

重复步骤 3 和 4，直到达到所需的终止时间 $t₁$。

龙格-库塔方法相对于欧拉方法具有更高的精度和稳定性。通过选择合适的阶数和步长，可以获得所需的数值精度。

# 29. Многошаговые методы. Метод Адамса.(多步方法,亚当斯（Adams）方法)
亚当斯方法利用前面已计算的多个步骤的函数值和导数来逼近下一个步骤的函数值。具体而言，亚当斯方法使用了之前的函数值和导数的加权组合来估计下一个步骤的函数值。其中最常用的是亚当斯-巴什福德（Adams-Bashforth）方法，其迭代公式如下：

$$y(tᵢ₊₁) = y(tᵢ) + h * (b₀f(tᵢ, y(tᵢ)) + b₁f(tᵢ₋₁, y(tᵢ₋₁)) + ... + bₖ*f(tᵢ₋ₖ, y(tᵢ₋ₖ)))$$

其中，$tᵢ$ 是当前时刻，$tᵢ₊₁$ 是下一个时刻，h 是步长，$y(tᵢ)$ 是当前时刻的函数值，f 是常微分方程的右侧函数，$b₀, b₁, ..., bₖ$ 是权重系数。

对于亚当斯-巴什福德方法，权重系数 $b₀, b₁, ..., bₖ$ 可以通过插值多项式的积分来获得。通常，使用的是线性插值多项式，即二阶方法，其中 k 的值为 1。

亚当斯方法需要之前的函数值和导数作为输入，并且需要一些初始的函数值来启动迭代过程。因此，在计算初始步骤时，可以使用其他数值积分方法（如欧拉方法或龙格-库塔方法）来近似获得初始值。

亚当斯方法是一种高阶的多步方法，可以提供较高的数值精度。

# 30. Многошаговые методы. Метод Милна.(米尔恩（Milne）方法)
米尔恩方法是一种四步多步方法，通过使用之前已计算的多个步骤的函数值和导数来逼近下一个步骤的函数值。具体步骤如下：

给定初始条件，即初始时刻 t₀ 和初始值 y₀。

使用其他数值方法（如欧拉方法或龙格-库塔方法）计算初始步骤的函数值。

在初始步骤的基础上，使用米尔恩方法进行迭代计算。对于每个时间步长 h，迭代公式如下：

a) 根据当前时刻 $tᵢ$ 的函数值和导数，使用亚当斯-巴什福德方法计算下一个时刻 $tᵢ₊₁$ 的函数值的预测值 $y'ᵢ₊₁$。

b) 使用预测值 $y'ᵢ₊₁$ 和之前两个步骤的函数值和导数，进行加权平均来计算下一个时刻 $tᵢ₊₁$ 的函数值的修正值 $yᵢ₊₁$。

c) 使用修正值 $yᵢ₊₁$ 和当前时刻的导数，计算下一个时刻 $tᵢ₊₁$ 的导数值。

重复步骤 3，直到达到所需的终止时间。

米尔恩方法通过结合亚当斯-巴什福德方法的预测和修正步骤，可以提供较高的数值精度。然而，与其他多步方法一样，米尔恩方法对步长的选择比较敏感，并且可能对某些问题的稳定性有一定的限制。

